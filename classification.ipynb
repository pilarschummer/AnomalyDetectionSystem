{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMCQkI+NQag78rJrKUAIF3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NKY7_dC7Q5qs"},"outputs":[],"source":["import argparse\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.externals import joblib  # To save and load models\n","import numpy as np\n","\n","def main(model_name, dataset_file, new_data=None):\n","    df = pd.read_csv(dataset_file)\n","\n","    df.index = df['timestamp']\n","    metric_columns = ['bandwidth', 'throughput', 'congestion', 'packet_loss', 'latency', 'jitter', 'anomaly']\n","    df = df[metric_columns]\n","\n","    X = df.drop('anomaly', axis=1)\n","    y = df['anomaly']\n","\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","\n","    # Load model if it's an existing model\n","    if model_name in ['logistic_regression', 'random_forest', 'svm']:\n","        model = joblib.load(f\"{model_name}_model.pkl\")\n","    else:\n","        raise ValueError(\"Model name should be one of: logistic_regression, random_forest, svm\")\n","\n","    if new_data:\n","        new_data_list = new_data.split(',')\n","        new_data_array = np.array(new_data_list, dtype=float).reshape(1, -1)\n","        X_new_scaled = scaler.transform(new_data_array)\n","        prediction = model.predict(X_new_scaled)\n","        print(f\"Prediction for the new data using {model_name.capitalize()} model:\", prediction[0])\n","    else:\n","        predictions = model.predict(X_scaled)\n","        anomaly_percentage = (np.sum(predictions) / len(predictions)) * 100\n","        print(f\"Percentage of anomalies in the predictions of {model_name.capitalize()}: {anomaly_percentage}\")\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser(description='Train and evaluate a classification model.')\n","    parser.add_argument('model_name', type=str, help='Name of the model to use (logistic_regression, random_forest, svm)')\n","    parser.add_argument('dataset_file', type=str, help='Path to the dataset file')\n","    parser.add_argument('--new_data', nargs='+', type=float, help='New data for prediction (comma separated values)')\n","    args = parser.parse_args()\n","\n","    new_data = None\n","    if args.new_data:\n","        new_data = ','.join(map(str, args.new_data))\n","\n","    main(args.model_name, args.dataset_file, new_data)\n"]},{"cell_type":"code","source":["python classification.py logistic_regression dataset.csv --new_data 1.0 2.0 3.0 4.0 5.0 6.0"],"metadata":{"id":"VOrgli_PROMo"},"execution_count":null,"outputs":[]}]}